Title,Link,Paragraphs
"Google drops pledge not to use AI for weapons, surveillance",https://www.aljazeera.com/economy/2025/2/5/chk_google-drops-pledge-not-to-use-ai-for-weapons-surveillance,"['Tech giant says in updated ethics policy that it will use AI in line with ‘international law and human rights’.', 'Google has dropped a pledge not to use artificial intelligence for weapons or surveillance in its updated ethics policy on the powerful technology.', 'In its previous version of “AI Principles”, the California-based internet giant included a commitment not to pursue AI technologies that “cause or are likely to cause overall harm”, including weapons and surveillance that violates “internationally accepted norms”.', 'Google’s revised policy announced on Tuesday states that the company pursues AI “responsibly” and in line with “widely accepted principles of international law and human rights”, but does not include the previous language about weapons or surveillance.', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” Google DeepMind chief Demis Hassabis and research labs senior vice president James Manyika said in a blog post announcing the updated policy.', '“And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'Google did not immediately respond to Al Jazeera’s request for comment.', '', '', '', 'Google first published its list of AI principles in 2018 after employees protested against the firm’s participation in the United States Department of Defense’s Project Maven, which examined the use of AI to help the military identify targets for drone strikes.', 'Google opted not to renew its contract with the Pentagon following the backlash, which saw a number of staff members resign and thousands of others sign a petition decrying the company’s involvement in the project.', 'The tech giant announced later that year that it would no longer compete for a $10bn cloud computing contract with the Pentagon because it “couldn’t be assured” that it would align with its AI principles.', 'Google’s updated ethics policy comes after the chief executive of parent company Alphabet Inc, Sundar Pichai, joined tech leaders, including Amazon founder Jeff Bezos and Meta chief Mark Zuckerberg, in attending the January 20 inauguration of US President Donald Trump.', 'Hours after taking office, Trump rescinded an executive order by former US President Joe Biden that established certain guardrails for the rapidly developing technology.', 'Biden’s order required companies developing AI to share the results of safety tests with the government before releasing new technologies to the public.', 'Follow Al Jazeera English:']"
Google lifts ban on using AI for weapons,https://www.bbc.com/news/articles/cy081nqx2zjo,"[""Google's parent company has lifted a ban on artificial intelligence (AI) being used for developing weapons and surveillance tools after changing its long-standing principles."", 'Alphabet has rewritten its guidelines on how it will use AI, dropping a section which previously ruled out applications that were ""likely to cause harm"".', 'In a blog post Google defended the change, arguing that businesses and democratic governments needed to work together on AI that ""supports national security"".', 'It said: ""We believe democracies should lead in AI development, guided by core values like freedom, equality and respect for human rights.', '""And we believe that companies, governments and organisations sharing these values should work together to create AI that protects people, promotes global growth and supports national security,"" it added.', 'There is debate among AI experts and professionals over how the powerful new technology should be governed in broad terms, how far commercial gains should be allowed to determine its direction, and how best to guard against risks for humanity in general.', 'There is also controversy around the use of AI on the battlefield and in surveillance technologies.', ""The blog - written by senior vice president James Manyika and Demis Hassabis, who leads the AI lab Google DeepMind - said the company's original AI principles published in 2018 needed to be updated as the technology had evolved."", '""Billions of people are using AI in their everyday lives. AI has become a general-purpose technology, and a platform which countless organisations and individuals use to build applications.', '""It has moved from a niche research topic in the lab to a technology that is becoming as pervasive as mobile phones and the internet itself,"" the blog post said.', 'As a result baseline AI principles were also being developed, which could guide common strategies, it said.', 'Originally, long before the current surge of interest in the ethics of AI, Google\'s founders, Sergei Brin and Larry Page, said their motto for the firm was ""don\'t be evil"".', 'When the company was restructured under the name Alphabet Inc in 2015 the parent company switched to ""Do the right thing"".', 'Since then Google staff have sometimes pushed back against the approach taken by their executives.', 'In 2018, the firm did not renew a contract for AI work with the US Pentagon following a resignations and a petition signed by thousands of employees.', 'They feared ""Project Maven"" was the first step towards using artificial intelligence for lethal purposes.', ""The blog was published just ahead of Alphabet's end of year financial report, showing results that were weaker than market expectations, and knocking back its share price."", 'That was despite a 10% rise in revenue from digital advertising, its biggest earner, boosted by US election spending.', 'In its earnings report the company said it would spend $75bn ($60bn) on AI projects this year, 29% more than Wall Street analysts had expected.', 'The company is investing in the infrastructure to run AI, AI research, and applications such as AI-powered search.', 'The sensors are at 40 places across the West Midlands at high-risk junctions, authorities say.', ""The document charred by the eruption of Mount Vesuvius is being 'unwrapped' using X-ray scans and AI."", 'A Chinese startup has built a low-cost AI model using less technologically advanced chips.', 'The Australian government says the Chinese AI app is a threat to it and its assets.', 'Almost 700,000 women to be recruited to study as government fires starting gun on cancer strategy.', 'Copyright 2025 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.', ' ', '']"
Google drops pledge not to use AI for weapons or surveillance,https://www.washingtonpost.com/technology/2025/02/04/google-ai-policies-weapons-harm/,"['In 2018, the company introduced policies that excluded applying AI in ways “likely to cause overall harm.” Now that promise is gone.', '', '', '']"
Google drops pledge on not using AI for weapons,https://www.richmondandtwickenhamtimes.co.uk/news/national/24911104.google-drops-pledge-not-using-ai-weapons/,"['Google has removed a pledge from its artificial intelligence (AI) principles that had said the company would not use the technology to develop weapons.', 'The technology giant has rewritten the principles that guide its development and use of AI – which are published online – but a section pledging not to develop tech “that cause or are likely to cause harm” has now been removed.', 'That section had said the firm would not pursue applications in the areas of weapons or “that gather or use information for surveillance violating internationally accepted norms”.', 'Instead, the newly streamlined principles now feature a section on “responsible development and deployment” which says the tech giant will implement “appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.”', 'In a blog post, Google senior vice president James Manyika and Sir Demis Hassabis, who leads the firm’s AI lab, Google DeepMind, said the company needed to update its AI principles as they had been first published in 2018 and the technology has “evolved rapidly” since then.', '“Billions of people are using AI in their everyday lives. AI has become a general-purpose technology, and a platform which countless organisations and individuals use to build applications,” they said.', '“It has moved from a niche research topic in the lab to a technology that is becoming as pervasive as mobile phones and the internet itself; one with numerous beneficial uses for society and people around the world, supported by a vibrant AI ecosystem of developers.”', 'They said this had meant increased international collaborative efforts on common principles, which the blog post said Google was “encouraged” by.', 'But Mr Manyika and Sir Demis said “global competition” for AI leadership was taking place within an “increasingly complex geopolitical landscape”.', 'As we make progress towards AGI, developing AI needs to be both innovative and safe. ⚖️', 'To help ensure this, we’ve made updates to our Frontier Safety Framework – our set of protocols to help us stay ahead of possible severe risks.', 'Find out more → https://t.co/YwtVDqQWW9 pic.twitter.com/LbHMdInAHQ', '— Google DeepMind (@GoogleDeepMind) February 4, 2025', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” they said.', '“And we believe that companies, governments, and organisations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'There is an ongoing debate among AI experts, governments, regulators, tech firms and academics about how the development powerful emerging technology should be monitored or regulated.', 'Previous international summits have seen countries and tech firms sign non-binding agreements to develop AI “responsibly”, but no binding international law on the issue is yet in place.', 'In the past, Google’s contracts to provide technology, such as cloud services, to the US and Israeli military have sparked internal protests from employees.', '', '', ""This website and associated newspapers adhere to the Independent Press Standards Organisation's Editors' Code of Practice. If you have a complaint about the editorial content which relates to inaccuracy or intrusion, then please contact the editor here. If you are dissatisfied with the response provided you can contact IPSO here"", '© 2001-2025. Newsquest Media Group Ltd, 1st Floor, Chartist Tower, Upper Dock Street, Newport, Wales, NP20 1DW | 01676637 |', '', '', '', '', '']"
Google no longer promises to refrain from using AI in military weaponry,https://www.neowin.net/news/google-no-longer-promises-to-refrain-from-using-ai-in-military-weaponry/,"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'David Uzondu · Feb 4, 2025 17:38 EST\n6', ""Artificial Intelligence is now a trending topic, thanks in no small part to the launch and virality of LLM chatbots like the U.S.'s ChatGPT and the stock market-crashing DeepSeek from China."", 'The popularity of these tools has led to concerns about how they will affect humans across various industries, including people who are unfamiliar with the term ""Artificial Intelligence.""', ""There's some risk involved with AI systems, especially when it comes to their potential to deepen misinformation, privacy violations, over-dependence, and, of course, warfare."", 'As such, top AI leaders are constantly working hard to keep AI safe for everyone. Google has published a ""Responsible AI Progress Report"" every year for six years now, and today, it has released the progress report for 2024.', ""In the blog post announcing the publication of the report, Google mentioned that it has updated its Frontier Safety Framework. If you don't know what that is, it's a set of protocols developed by Google DeepMind to proactively identify and mitigate potential risks associated with advanced AI models. The updated framework includes:"", 'Alongside the update to the safety framework, Google reiterated its belief that democracies should lead in the development of AI, guided by values like ""freedom, equality, and respect for human rights."" In addition, it said it was updating its AI Principles, which were publicly released back in 2018.', ""When you take a look at the full AI Principles page, you'll notice that there's no mention of AI use in weapons development."", 'This copy of the page, archived 22 Feb 2024 04:19:46 UTC, has a part that explicitly mentions weapons and Google\'s promise not to ""design or deploy AI"" in that area:', 'Weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.', 'That line is now gone in the updated principles. The updated principles will instead focus on the following three core tenets:', 'Google has not acknowledged the removal of the pledge not to use AI in weapons development, but this is something its employees have expressed strong opposition to in the past.', 'For example, in 2018, almost 4,000 Google employees signed a letter urging the company to terminate its contract with the U.S. Department of Defense, known as Project Maven, which involved using AI to analyze drone footage.', ""Likewise, last year, employees from Google DeepMind signed a letter urging the tech giant to end ties with military organizations. The letter cited the company's AI principles, arguing that its involvement with military and weapon manufacturing went against and violated its now-removed promise not to use AI in weaponry."", 'Image via Depositphotos.com', 'David Uzondu · 2 hours ago 3', 'David Uzondu · Jan 23, 2025 2', 'David Uzondu · Jan 14, 2025 1', 'Pradeep Viswanathan · Oct 31, 2024 4', 'Login or Sign Up to read and post a comment.', '', '', '', '', '', '', '', '', '', '', '', '', '', '© Since 2000 Neowin® All trademarks mentioned are the property of their respective owners.']"
Google is ready to work on AI weapons now,https://www.platformer.news/google-ai-principles-military-safety/,"['The company’s promise to avoid building AI applications that cause harm has been deleted', 'Already have an account? Sign in', ""OpenAI's new research tool still makes mistakes — but in its speed and average quality of analysis, it represents a remarkable step forward"", 'The company’s decision to expose chain of thought is a surprise hit — and a reminder of how far AI product teams have left to go', 'The Chinese AI upstart has rattled Silicon Valley — but how much the game has changed remains to be seen', 'Hands on with Operator — a promising but frustrating new frontier for artificial intelligence', 'News at the intersection of Silicon Valley and democracy. On Monday, Tuesday, and Thursday at 5PM Pacific.', '']"
Google's AI Policy Shift: No More Ban On Weapons And Surveillance Tech,https://www.ndtv.com/world-news/google-drops-ai-ban-on-weapons-and-surveillance-in-major-ethics-shift-7637918,"['In a significant departure from its earlier commitments to not use artificial intelligence in the fields of weapons or surveillance, Google has updated its ethical guidelines on the same.  ', ""The company's original 2018 AI principles explicitly prohibited AI applications in four areas: weapons, surveillance, technologies that could cause overall harm, and uses violating international law and human rights."", ""Now, in a blog post, Demis Hassabis, head of AI at Google, and James Manyika, senior vice president for technology and society, explained the change. They pointed to AI's growing presence and the need for companies in democratic nations to work with governments and national security."", '""There\'s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,"" Mr Hassabis and Mr Manyika wrote. ""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights.""', 'The updated principles focus on human oversight and feedback to make sure AI follows international law and human rights standards. Google also promises to test AI systems to reduce any unintended harmful effects.', '', '', 'This change is a major shift from Google\'s earlier position, which drew attention in 2018 when the company faced internal protests over its Pentagon contract. Known as Project Maven, the contract involved using Google\'s AI to analyse drone footage. Thousands of employees signed an open letter urging Google not to be involved in military projects, saying, ""We believe that Google should not be in the business of war."" As a result, Google chose not to renew the contract.', ""Since OpenAI launched ChatGPT in 2022, AI has advanced rapidly, but regulations have struggled to keep pace. This shift has led Google to ease its self-imposed restrictions. James Manyika and Demis Hassabis noted that AI frameworks from democratic nations have helped shape Google's understanding of AI's risks and potential."", 'Track Latest News Live on NDTV.com and get news updates from India and around the world']"
Google owner drops promise not to use AI for weapons,https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons,"['Alphabet guidelines no longer refer to not pursuing technologies that could ‘cause or are likely to cause overall harm’', 'The Google owner, Alphabet, has dropped its pledge not to use artificial intelligence for purposes such as developing weapons and surveillance tools.', 'The US technology company said on Tuesday, just before it reported lower than forecast earnings, that it had updated its ethical guidelines around AI, and they no longer refer to not pursuing technologies that could “cause or are likely to cause overall harm”.', 'Google’s AI head, Demis Hassabis, said the guidelines were being overhauled in a changing world and that AI should protect “national security”.', 'In a blogpost defending the move, Hassabis and the company’s senior vice-president for technology and society, James Manyika, wrote that as global competition for AI leadership increases, the company believes “democracies should lead in AI development” that is guided by “freedom, equality, and respect for human rights”.', 'They added: “We believe that companies, governments, and organisations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'Google’s motto when it first floated was “don’t be evil”, although this was later downgraded in 2009 to a “mantra” and was not included in the code of ethics of Alphabet when the parent company was created in 2015.', 'The rapid growth of AI has prompted a debate about how the new technology should be governed, and how to guard against its risks.', 'The British computer scientist Stuart Russell has warned of the dangers of developing autonomous weapon systems, and argued for a system of global control, speaking in a Reith lecture on the BBC.', 'The Google blogpost argued that since the company first published its AI principles in 2018, the technology had evolved rapidly. “Billions of people are using AI in their everyday lives. AI has become a general-purpose technology, and a platform which countless organisations and individuals use to build applications,” Hassabis and Manyika wrote.', 'Sign up to Business Today', ""Get set for the working day – we'll point you to all the business news and analysis you need every morning"", '', '“It has moved from a niche research topic in the lab to a technology that is becoming as pervasive as mobile phones and the internet itself; one with numerous beneficial uses for society and people around the world, supported by a vibrant AI ecosystem of developers.”', 'Google’s shares fell 7.5% in after-hours trading, after Tuesday’s report that it made $96.5bn (£77bn) in consolidated revenue, slightly below analyst expectations of $96.67bn.']"
Google Removes Its Vow Not to Use AI for Weapons,https://www.newser.com/story/363738/google-is-no-longer-promising-it-wont-use-ai-for-weapons.html,"['Google\'s artificial intelligence policy previously included a vow that the company would not pursue AI applications involving weapons, surveillance, technologies that ""cause or are likely to cause overall harm,"" or anything that could violate international law or human rights. That language is now missing from the company\'s newly updated AI guiding principles, the Washington Post reports. The principles had originally been published in 2018, CNN reports. Since then, massive strides have been made with AI technology. Google defended the changes to its policy in a blog post, the BBC reports. A key quote:', '', '', '', '', '', '', '', '', '', '', '']"
Google's latest change to its AI policies signals how Silicon Valley is warming up to the defense industry,https://www.businessinsider.com/google-changes-its-ai-policy-defense-tech-2025-2,"[""Google updated its ethical guidelines for artificial intelligence in a blog post on Tuesday, removing the company's previous vows to not use its technology to build weapons or surveillance tools."", 'In 2018, the company outlined AI ""applications we will not pursue."" These included weapons and ""technologies that gather or use information for surveillance violating internationally accepted norms,"" as well as ""technologies that cause or are likely to cause overall harm"" and ""technologies whose purpose contravenes widely accepted principles of international law and human rights.""', 'The 2018 post now includes an appended note at the top of the page that says the company has updated its AI principles in a new post, which does not mention the previous guidelines against using AI for weapons and some surveillance technologies.', 'The company first published these AI guidelines in 2018 after thousands of Google employees protested its involvement in Project Maven, an AI project that Google and the US Department of Defense collaborated on. After over 4,000 workers signed a petition demanding that Google stop working on Project Maven and promise never to again ""build warfare technology,"" the company decided not to renew its contract to build AI tools for the Pentagon.', ""James Manyika, Google's senior vice president for technology and society, and Demis Hassabis, the CEO of Google DeepMind, said in a blog post that democratic nations and companies should work together in leveraging AI that strengthens homeland security:"", '""There\'s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,"" the executives wrote. ""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights. And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.""', 'A spokesperson from Google did not immediately respond to a request for comment.', 'Although many in Silicon Valley previously steered clear of US military contracts, this move — in the backdrop of the Trump administration, rising US-China tensions, and the Russian-Ukraine war — is part of a broader shift among tech companies and startups moving toward offering their proprietary technology, including artificial intelligence tools, for defense purposes.', 'Defense tech companies and startups have been optimistic that the industry is poised for success during President Donald Trump\'s second term. In November of last year, Anduril cofounder Palmer Luckey said in an interview with Bloomberg TV of Trump that it is ""good to have someone inbound who is deeply aligned with the idea that we need to be spending less on defense while still getting more: that we need to do a better job of procuring the defense tools that protect our country.""', ""Late last year, Palantir and Anduril, which makes autonomous vehicles for military use, held discussions with other defense companies and startups, including SpaceX, ScaleAI, and OpenAI, to form a bidding group for the US government's defense contracts."", '']"
Google parent Alphabet rewrites AI principles,https://www.proactiveinvestors.co.uk/companies/news/1065708,"['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Published: 08:47 05 Feb 2025 GMT', 'Alphabet Inc (NASDAQ:GOOG), Google’s parent company, has rewritten its AI principles, removing a previous commitment not to use AI for weapons or surveillance.', 'It has also dropped a rule against AI applications that are “likely to cause harm”.', 'In a blog post, Google executives James Manyika and Demis Hassabis defended the change, arguing that AI should support national security and that businesses should work with democratic governments to guide its development.', 'Helix Exploration re-entering Clink well at Ingomar Dome as it progresses Rudyard project', 'They said the geopolitical landscape is becoming more complex, requiring updated policies.', 'This shift follows Google’s move away from its original “Don’t be evil” motto, which was quietly dropped when Alphabet was formed in 2015 and replaced with “Do the right thing.”', 'Originally introduced in 2018, Google’s AI principles were revised as AI has become a core technology, much like the internet or mobile phones.', 'The company is now investing $75 billion in AI projects this year, focusing on infrastructure, research, and AI-powered search tools like its Gemini platform.', 'Sign up to receive alerts and news direct to your inbox', 'London’s blue chips were little changed as trading kicked off on Wednesday, with the FTSE 100 trading in and out of the black. GSK PLC headed the early risers with a 6.3% gain after results saw its long-term sales target upgraded. Sales were expected to exceed £40 billion by 2031, against...', '© Proactive Group Holdings Inc, 2025', 'Proactive Investors Limited, trading as “Proactiveinvestors United Kingdom” is registered in England with the Company Registration number 05639690. Group VAT registration number 872070825. You can contact us here.', 'Market Indices, Commodities and Regulatory News Headlines copyright © Morningstar. Data delayed 15 minutes unless otherwise indicated. Terms of use.', '']"
Google pledge against using AI for weapons vanishes,https://www.averyjournal.com/news/national/google-pledge-against-using-ai-for-weapons-vanishes/article_1b276cb3-b557-5eae-919f-43f70acc998d.html,"['', '', ""Google's original principles when it came to developing artificial intelligence were not to use it for weapons or surveillance that could infringe on people's rights"", '', 'Originally published on doc.afp.com, part of the BLOX Digital Content Exchange.', 'Log In', '', '', '', ""We'll send breaking news and news alerts to you as they happen!"", '', '', ""We'll send breaking news and news alerts to you as they happen!"", '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Learn more about your privacy options', '', '', '']"
"Google removes pledge to not use AI for weapons, surveillance",https://www.cnbc.com/2025/02/04/google-removes-pledge-to-not-use-ai-for-weapons-surveillance.html,"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Google\nhas removed a pledge to abstain from using AI for potentially harmful applications, such as weapons and surveillance, according to the company’s updated “AI Principles.”', 'A prior version of the company’s AI principles said the company would not pursue “weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people,” and “technologies that gather or use information for surveillance violating internationally accepted norms.”', 'Those objectives are no longer displayed on its AI Principles website.', '“There’s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,” reads a Tuesday blog post co-written by Demis Hassabis, CEO of Google DeepMind. “We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights.”', 'The company’s updated principles reflect Google’s growing ambitions to offer its AI technology and services to more users and clients, which has included governments. The change is also in line with increasing rhetoric out of Silicon Valley leaders about a winner-take-all AI race between the U.S. and China, with Palantir’s CTO Shyam Sankar saying Monday that “it’s going to be a whole-of-nation effort that extends well beyond the DoD in order for us as a nation to win.”', 'The previous version of the company’s AI principles said Google would “take into account a broad range of social and economic factors.” The new AI principles state Google will “proceed where we believe that the overall likely benefits substantially exceed the foreseeable risks and downsides.”', 'In its Tuesday blog post, Google said it will “stay consistent with widely accepted principles of international law and human rights — always evaluating specific work by carefully assessing whether the benefits substantially outweigh potential risks.”', 'The new AI principles were first reported by The Washington Post on Tuesday, ahead of Google’s fourth-quarter earnings. The company’s results missed Wall Street’s revenue expectations and drove shares down as much as 9% in after-hours trading.', 'Google established its AI principles in 2018 after declining to renew a government contract called Project Maven, which helped the government analyze and interpret drone videos using artificial intelligence. Prior to ending the deal, several thousand employees signed a petition against the contract and dozens resigned in opposition to Google’s involvement. The company also dropped out of the bidding for a $10 billion Pentagon cloud contract in part because the company “couldn’t be sure” it would align with the company’s AI principles, it said at the time.', 'Touting its AI technology to clients, Pichai’s leadership team has aggressively pursued federal government contracts, which has caused heightened strain in some areas within Google’s outspoken workforce.', '“We believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,” Google’s Tuesday blog post said.', 'Google last year terminated more than 50 employees after a series of protests against Project Nimbus, a $1.2 billion joint contract with Amazon that provides the Israeli government and military with cloud computing and AI services. Executives repeatedly said the contract didn’t violate any of the company’s “AI principles.”', 'However, documents and reports showed the company’s agreement allowed for giving Israel AI tools that included image categorization, object tracking, as well as provisions for state-owned weapons manufacturers. The New York Times in December reported that four months prior to signing on to Nimbus, Google officials expressed concern that signing the deal would harm its reputation and that “Google Cloud services could be used for, or linked to, the facilitation of human rights violations.”', 'Meanwhile, the company had been cracking down on internal discussions around geopolitical conflicts like the war in Gaza.', 'Google announced updated guidelines for its Memegen internal forum in September that further restricted political discussions about geopolitical content, international relations, military conflicts, economic actions and territorial disputes, according to internal documents viewed by CNBC at the time. ', 'Google did not immediately respond to a request for comment.', 'WATCH: Google’s uphill AI battle in 2025', 'Got a confidential news tip? We want to hear from you.', 'Sign up for free newsletters and get more CNBC delivered to your inbox', 'Get this delivered to your inbox, and more info about our products and services.', '© 2025 CNBC LLC. All Rights Reserved. \nA Division of NBCUniversal', 'Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.', 'Data also provided by', '', '', '', '', '', '', '', '']"
Google pledge against using AI for weapons vanishes,https://www.yahoo.com/news/google-pledge-against-using-ai-034126464.html,"['', '', '', '', '', 'Google on Tuesday updated its principles when it comes to artificial intelligence, removing vows not to use the technology for weapons or surveillance.', 'Revised AI principles were posted just weeks after Google chief executive Sundar Pichai and other tech titans attended the inauguration of US President Donald Trump.', ""When asked by AFP about the change, a Google spokesperson referred to a blog post outlining the company's AI principles that made no mention of the promises, which Pichai first outlined in 2018."", '""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,"" read an updated AI principles blog post by Google DeepMind chief Demis Hassabis and research labs senior vice president James Manyika.', '""And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,"" it continued.', 'Pichai had previously stated that the company would not design or deploy the technology for weapons designed to hurt people or ""that gather or use information for surveillance violating internationally accepted norms.""', 'That wording was gone from the updated AI principles shared by Google on Tuesday.', 'Upon taking office, Trump quickly rescinded an executive order by his predecessor, former president Joe Biden, mandating safety practices for AI.', 'Companies in the race to lead the burgeoning AI field in the United States now have fewer obligations to adhere to, such as being required to share test results signalling the technology has serious risks to the nation, its economy or its citizens.', 'Google noted in its blog post that it publishes an annual report about its AI work and progress.', '""There\'s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,"" Hassabis and Manyika said in their post.', '""Billions of people are using AI in their everyday lives.""', ""Google's original AI principles were published after employee backlash to its involvement in a Pentagon research project looking into using AI to improve the ability of weapons systems to identify targets."", 'Google ended its involvement in the project.', 'gc-juj/jgc']"
Google pledge against using AI for weapons vanishes,https://www.citizentribune.com/news/national/google-pledge-against-using-ai-for-weapons-vanishes/article_3c91ba64-234d-54f1-b721-ef0f03337eb9.html,"['', '', '', '', '', '', '', '', '', '', '', '', '', ""Google's original principles when it came to developing artificial intelligence were not to use it for weapons or surveillance that could infringe on people's rights"", 'Google on Tuesday updated its principles when it comes to artificial intelligence, removing vows not to use the technology for weapons or surveillance.', 'Revised AI principles were posted just weeks after Google chief executive Sundar Pichai and other tech titans attended the inauguration of US President Donald Trump.', ""When asked by AFP about the change, a Google spokesperson referred to a blog post outlining the company's AI principles that made no mention of the promises, which Pichai first outlined in 2018."", '""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,"" read an updated AI principles blog post by Google DeepMind chief Demis Hassabis and research labs senior vice president James Manyika.', '""And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,"" it continued.', 'Pichai had previously stated that the company would not design or deploy the technology for weapons designed to hurt people or ""that gather or use information for surveillance violating internationally accepted norms.""', 'That wording was gone from the updated AI principles shared by Google on Tuesday.', 'Upon taking office, Trump quickly rescinded an executive order by his predecessor, former president Joe Biden, mandating safety practices for AI.', 'Companies in the race to lead the burgeoning AI field in the United States now have fewer obligations to adhere to, such as being required to share test results signalling the technology has serious risks to the nation, its economy or its citizens.', 'Google noted in its blog post that it publishes an annual report about its AI work and progress.', '""There\'s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,"" Hassabis and Manyika said in their post.', '""Billions of people are using AI in their everyday lives.""', ""Google's original AI principles were published after employee backlash to its involvement in a Pentagon research project looking into using AI to improve the ability of weapons systems to identify targets."", 'Google ended its involvement in the project.', 'gc-juj/jgc', 'Originally published on doc.afp.com, part of the BLOX Digital Content Exchange.', 'We offer a full suite of print and online subscription services for our customers. We offer day passes, monthly and yearly subscriptions.', 'Sign up for our free e-newsletters - delivered straight to your inbox.', '', '', 'Would you like to receive our newsletter?', ""Don't miss a golden opportunity! Local daily job listings delivered straight to your inbox."", 'Local real estate listings sent Monday - Friday and Sunday at 8:00am.', ""Each day's obituaries delivered to your inbox."", ""The day's latest headlines sent Monday - Friday at 2:30pm and Sunday morning at 6am."", 'A round up of regional sports action from Saturday and late Friday night', 'Vibrant Magazine Articles Delivered Straight to Your In-Box Every Month', 'Seasonal and family recipes delivered weekly to your inbox - every Thursday.', 'Our Wink Magazine articles delivered straight to your inbox every month.', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Learn more about your privacy options', '', '', '']"
Google Drops Weapons and Surveillance Ban from AI Ethical Guidelines,https://www.thewrap.com/google-drops-weapons-and-surveillance-ban-from-ai-ethical-guidelines/,"['The company shared an update of its AI principles on Tuesday saying it will adhere to “widely accepted principles of international law and human rights”', 'Google has gone back on a previous pledge not to use AI for weapons and surveillance, The Washington Post reported on Tuesday. Policies about “applications we will not pursue” from 2018 have been deleted from the company’s AI principles.', '“As recently as Jan. 30 [the list of banned applications] included weapons, surveillance, technologies that ’cause or are likely to cause overall harm,’ and use cases contravening principles of international law and human rights, according to a copy hosted by the Internet Archive,” the Post reported.', 'When asked for comment, a Google spokesperson directed TheWrap to a blog post from the company’s head of AI Demis Hassabis and SVP for technology and society James Manyika that promises transparency in the latest technological developments.', '“We believe democracies should lead in AI development, guided by core values like freedom, equality and respect for human rights. And we believe that companies, governments and organizations sharing these values should work together to create AI that protects people, promotes global growth and supports national security,” the blog reads.', 'Google’s updated AI principles state that the company will use human oversight to make sure the use of its technology conforms to “widely accepted principles of international law and human rights.”', 'The company first published its AI principles in 2018 after employees protested a contract with the Pentagon that used Google’s computer vision algorithms to analyze drone footage. The contract was not renewed.', 'Thousands of employees signed a letter addressed to CEO Sundar Pichai that stated, “We believe that Google should not be in the business of war.”', '']"
Google Removes Pledge to Not Use AI for Weapons and Surveillance,https://www.binance.com/en/square/post/19892216553026,"['Google has removed a pledge from its artificial intelligence (AI) principles, which previously committed to avoiding the development of AI for weapons and surveillance. The change, first reported by The Washington Post on February 4, signals the company’s approach to national security partnerships as AI becomes more integrated into military and intelligence operations.', 'In a blog post published on Tuesday, Google executives stated that the update was necessary due to AI’s increasing prevalence and the need for technology companies based in democratic nations to support government and defense clients. ', 'We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights. And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.', 'Google', 'The company’s previous AI ethos, enacted in 2018, explicitly rejected “weapons or other technologies whose principal purpose or implementation is to cause or directly “injury people” and “technologies that gather or use information for surveillance violating internationally accepted norms,” have now been removed from its AI Principles website.', 'Google updates AI principles for “national security”', 'Google’s revised principles now state that the company will proceed with AI development where the “overall likely benefits substantially exceed the foreseeable risks and downsides.” The update marks a notable departure from its earlier stance, which emphasized broad ethical considerations and the avoidance of AI applications that could cause harm.', 'Moreover, US tech industry leaders are seemingly working towards improving the country’s AI capabilities, in order to charge ahead in the technological “cold war” between the United States and China. ', 'On Monday, Palantir’s Chief Technology Officer, Shyam Sankar, described the AI race as a “whole-of-nation” effort that needs to go past the walls of the Department of Defense, for “America to win.”', 'For years, Google’s restrictions on national security applications of AI made it an outlier among leading AI firms. Other tech giants, including Microsoft and Amazon, have maintained long-standing partnerships with the Pentagon, but newer AI companies are warming up to military ties. ', 'Late last year, OpenAI, the creator of ChatGPT, announced a collaboration with defense contractor Anduril to develop AI technology for the U.S. military. Similarly, Anthropic, the company behind the Claude chatbot, partnered with Palantir to provide AI services to U.S. intelligence agencies through Amazon Web Services.', 'Michael Horowitz, a political science professor at the University of Pennsylvania and former Pentagon official well-versed in emerging technologies, told the WP that Google’s policy change is part of a broader trend. ', '“Google’s announcement is more evidence that the relationship between the U.S. technology sector and the Defense Department continues to get closer, including leading AI companies,” he said. “It makes sense that Google has updated its policy to reflect the new reality.”', 'Controversy over Google’s military and surveillance contracts', 'In 2023, as reported by CNN, Google let go of over 50 employees following a series of protests against Project Nimbus, a $1.2 billion joint cloud computing and AI contract with Amazon to provide services to the Israeli government and military. Executives repeatedly defended the deal, avowing that it did not violate Google’s AI principles.', 'However, documents revealed by The New York Times in December suggested that Google’s agreement with Israel included AI capabilities such as image categorization and object tracking, as well as potential provisions for state-owned weapons manufacturers. ', 'According to the Times, four months before signing onto Project Nimbus, Google executives had privately raised concerns that the deal could damage the company’s reputation and that its cloud services might be linked to human rights violations.', 'At the same time, Google has faced criticism for restricting internal discussions about geopolitical conflicts, including the war in Gaza. Some employees accused the company of suppressing debate while simultaneously deepening its involvement in defense and surveillance-related AI contracts.', 'On social media, following Google’s updated AI principles, netizens are debating whether the tech startup’s plan is to protect the interests of Americans, or its just a ploy to take the biggest piece of cake in government defense contracts.', '“Sooooo….is AI going to be used for US weapons and surveillance or sold to top bidder?” One X user asked.', 'Cryptopolitan Academy: FREE Web3 Resume Cheat Sheet - Download Now']"
Google drops pledge on not using AI for weapons,https://www.thetottenhamindependent.co.uk/news/national/24911104.google-drops-pledge-not-using-ai-weapons/,"['Google has removed a pledge from its artificial intelligence (AI) principles that had said the company would not use the technology to develop weapons.', 'The technology giant has rewritten the principles that guide its development and use of AI – which are published online – but a section pledging not to develop tech “that cause or are likely to cause harm” has now been removed.', 'That section had said the firm would not pursue applications in the areas of weapons or “that gather or use information for surveillance violating internationally accepted norms”.', 'Instead, the newly streamlined principles now feature a section on “responsible development and deployment” which says the tech giant will implement “appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.”', 'In a blog post, Google senior vice president James Manyika and Sir Demis Hassabis, who leads the firm’s AI lab, Google DeepMind, said the company needed to update its AI principles as they had been first published in 2018 and the technology has “evolved rapidly” since then.', '“Billions of people are using AI in their everyday lives. AI has become a general-purpose technology, and a platform which countless organisations and individuals use to build applications,” they said.', '“It has moved from a niche research topic in the lab to a technology that is becoming as pervasive as mobile phones and the internet itself; one with numerous beneficial uses for society and people around the world, supported by a vibrant AI ecosystem of developers.”', 'They said this had meant increased international collaborative efforts on common principles, which the blog post said Google was “encouraged” by.', 'But Mr Manyika and Sir Demis said “global competition” for AI leadership was taking place within an “increasingly complex geopolitical landscape”.', 'As we make progress towards AGI, developing AI needs to be both innovative and safe. ⚖️', 'To help ensure this, we’ve made updates to our Frontier Safety Framework – our set of protocols to help us stay ahead of possible severe risks.', 'Find out more → https://t.co/YwtVDqQWW9 pic.twitter.com/LbHMdInAHQ', '— Google DeepMind (@GoogleDeepMind) February 4, 2025', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” they said.', '“And we believe that companies, governments, and organisations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'There is an ongoing debate among AI experts, governments, regulators, tech firms and academics about how the development powerful emerging technology should be monitored or regulated.', 'Previous international summits have seen countries and tech firms sign non-binding agreements to develop AI “responsibly”, but no binding international law on the issue is yet in place.', 'In the past, Google’s contracts to provide technology, such as cloud services, to the US and Israeli military have sparked internal protests from employees.', '', '', ""This website and associated newspapers adhere to the Independent Press Standards Organisation's Editors' Code of Practice. If you have a complaint about the editorial content which relates to inaccuracy or intrusion, then please contact the editor here. If you are dissatisfied with the response provided you can contact IPSO here"", '© 2001-2025. Newsquest Media Group Ltd, 1st Floor, Chartist Tower, Upper Dock Street, Newport, Wales, NP20 1DW | 01676637 |', '', '', '', '', '']"
Google torpedoes 'no AI for weapons' rules,https://www.theregister.com/2025/02/05/google_ai_principles_update/,"['Google has published a new set of AI principles that don’t mention its previous pledge not to use the tech to develop weapons or surveillance tools that violate international norms.', 'The Chocolate Factory\'s original AI principles, outlined by CEO Sundar Pichai in mid-2018, included a section on ""AI applications we will not pursue."" At the top of the list was a commitment not to design or deploy AI for ""technologies that cause or are likely to cause overall harm"" and a promise to weigh risks so that Google would “proceed only where we believe that the benefits substantially outweigh the risks”.', 'Other AI applications Google vowed to steer clear of that year included:', ""Those principles were published two months after some 3,000 Googlers signed a petition opposing the web giant's involvement in a Pentagon program called Project Maven that used Google's AI to analyze drone footage."", 'The same month Pichai published Google’s AI principles post, the search and ads giant decided not to renew its contract for Project Maven after its expiry in 2019.', 'In December 2018 the Chrome maker challenged other tech firms building AI to follow its lead and develop responsible tech that ""avoids abuse and harmful outcomes.""', 'On Tuesday this week, Pichai\'s 2018 blog post added a notice advising readers that, as of February 4, 2025, Google has ""made updates to our AI Principles"" that can be found at AI.Google.', ""The Chocolate Factory's updated AI principles center on three things: Bold innovation; responsible development and deployment; and collaborative process."", ""These updated principles don't mention applications Google won’t work on nor pledges to not use AI for harmful purposes or weapons development."", 'They do state that Google will develop and deploy AI models and apps “where the likely overall benefits substantially outweigh the foreseeable risks.""', 'There’s also a promise to always use ""appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights,"" plus a pledge to invest in ""industry-leading approaches to advance safety and security research and benchmarks, pioneering technical solutions to address risks, and sharing our learnings with the ecosystem.""', 'The Big G has also promised ""rigorous design, testing, monitoring, and safeguards to mitigate unintended or harmful outcomes and avoid unfair bias"" along with “promoting privacy and security, and respecting intellectual property rights.""', 'A section of the new principles offers the following example of how they will operate:', 'We identify and assess AI risks through research, external expert input, and red teaming. We then evaluate our systems against safety, privacy, and security benchmarks. Finally, we build mitigations with techniques such safety tuning, security controls, and robust provenance solutions.', 'Also on Tuesday, Google published its annual Responsible AI Progress Report, which addresses the current AI arms race.', '""There\'s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,"" said James Manyika, SVP for research, labs, technology and society, and Demis Hassabis, co-founder and CEO of Google DeepMind.', '""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,"" the Google execs continued. ""And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.""', 'Google will continue to pursue ""AI research and applications that align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights,"" the duo added.', ""Google did not immediately respond to The Register's inquiries, including if there are any AI applications it won't pursue under the updated AI principles, why it removed the weapons and surveillance mentions from its banned uses, and if it has any specific policy or guidelines around how its AI can be used for these previously not-OK purposes."", 'We will update this article if and when we hear back from the Chocolate Factory.', ""Meanwhile, Google's rivals happily provide machine-learning models and IT services to the United States military and government, at least. Microsoft has argued America's armed forces deserve the best tools, which in the Windows giant's mind is its technology. OpenAI, Amazon, IBM, Oracle, and Anthropic work with Uncle Sam on various projects. Even Google these days. The internet titan is just less openly squeamish about it. ®"", 'Send us news', 'The Register Biting the hand that feeds IT', 'Copyright. All rights reserved © 1998–2025']"
Google surprisingly signals a major change to how it might utilize AI,https://www.phonearena.com/news/google-changes-pledge-against-using-ai-to-build-weapons_id167300,"['', '', '', '', '']"
Google drops pledge on not using AI for weapons,https://www.independent.co.uk/business/google-drops-pledge-on-not-using-ai-for-weapons-b2692533.html,"['', '', '', ""From reproductive rights to climate change to Big Tech, The Independent is on the ground when the story is developing. Whether it's investigating the financials of Elon Musk's pro-Trump PAC or producing our latest documentary, 'The A Word', which shines a light on the American women fighting for reproductive rights, we know how important it is to parse out the facts from the messaging."", '', '', 'Google has removed a pledge from its artificial intelligence (AI) principles that had said the company would not use the technology to develop weapons.', 'The technology giant has rewritten the principles that guide its development and use of AI – which are published online – but a section pledging not to develop tech “that cause or are likely to cause harm” has now been removed.', 'That section had said the firm would not pursue applications in the areas of weapons or “that gather or use information for surveillance violating internationally accepted norms”.', 'Instead, the newly streamlined principles now feature a section on “responsible development and deployment” which says the tech giant will implement “appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.”', 'In a blog post, Google senior vice president James Manyika and Sir Demis Hassabis, who leads the firm’s AI lab, Google DeepMind, said the company needed to update its AI principles as they had been first published in 2018 and the technology has “evolved rapidly” since then.', '“Billions of people are using AI in their everyday lives. AI has become a general-purpose technology, and a platform which countless organisations and individuals use to build applications,” they said.', '“It has moved from a niche research topic in the lab to a technology that is becoming as pervasive as mobile phones and the internet itself; one with numerous beneficial uses for society and people around the world, supported by a vibrant AI ecosystem of developers.”', 'They said this had meant increased international collaborative efforts on common principles, which the blog post said Google was “encouraged” by.', 'But Mr Manyika and Sir Demis said “global competition” for AI leadership was taking place within an “increasingly complex geopolitical landscape”.', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” they said.', '“And we believe that companies, governments, and organisations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'There is an ongoing debate among AI experts, governments, regulators, tech firms and academics about how the development powerful emerging technology should be monitored or regulated.', 'Previous international summits have seen countries and tech firms sign non-binding agreements to develop AI “responsibly”, but no binding international law on the issue is yet in place.', 'In the past, Google’s contracts to provide technology, such as cloud services, to the US and Israeli military have sparked internal protests from employees.', '']"
Google erases promise not to use AI technology for weapons or surveillance,https://www.cnn.com/2025/02/04/business/google-ai-weapons-surveillance/index.html,"['Markets', '', 'Fear & Greed Index', 'Latest Market News', '', '', 'Google’s updated, public AI ethics policy removes its promise that it won’t use the technology to pursue applications for weapons and surveillance.', 'In a previous version of the principles seen by CNN on the internet archive Wayback Machine, the company included applications it won’t pursue. One such category was weapons or other technology intended to injure people. Another was technology used to surveil beyond international norms.', 'That language is gone on the updated principles page.', 'Since OpenAI launched chatbot ChatGPT in 2022, the artificial intelligence race has advanced at a dizzying pace. While AI has boomed in use, legislation and regulations on transparency and ethics in AI have yet to catch up – and now Google seems to have loosened self-imposed restrictions.', 'In a blog post Tuesday, senior vice president of research, labs, technology & society James Manyika and Google DeepMind head Demis Hassabis said that AI frameworks published by democratic countries have deepened Google’s “understanding of AI’s potential and risks.”', '“There’s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape. We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” the blog post said.', 'The post continued, “and we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'Google first published its AI Principles in 2018, years before the technology became almost ubiquitous. Google’s update is a sharp reversal in values from those original published principles.', 'In 2018, Google dropped a $10 billion bid for a cloud computing Pentagon contract, saying at the time “we couldn’t be assured that it would align with our AI Principles.” More than 4,000 employees had signed a petition that year demanding “a clear policy stating that neither Google nor its contractors will ever build warfare technology,” and about a dozen employees resigned in protest.', 'CNN has reached out to Google for comment.', 'CNN’s Jordan Valinsky contributed to this report.', 'Most stock quote data provided by BATS. US market indices are shown in real time, except for the S&P 500 which is refreshed every two minutes. All times are ET. Factset: FactSet Research Systems Inc. All rights reserved. Chicago Mercantile: Certain market data is the property of Chicago Mercantile Exchange Inc. and its licensors. All rights reserved. Dow Jones: The Dow Jones branded indices are proprietary to and are calculated, distributed and marketed by DJI Opco, a subsidiary of S&P Dow Jones Indices LLC and have been licensed for use to S&P Opco, LLC and CNN. Standard & Poor’s and S&P are registered trademarks of Standard & Poor’s Financial Services LLC and Dow Jones is a registered trademark of Dow Jones Trademark Holdings LLC. All content of the Dow Jones branded indices Copyright S&P Dow Jones Indices LLC and/or its affiliates. Fair value provided by IndexArb.com. Market holidays and trading hours provided by Copp Clark Limited.', '© 2025 Cable News Network. A Warner Bros. Discovery Company. All Rights Reserved.\nCNN Sans ™ & © 2016 Cable News Network.', '', '', '', '', '']"
Google removes guidelines barring its AI from being used in surveillance and weapons: report,https://www.yahoo.com/news/google-removes-guidelines-barring-ai-013130630.html,"['', '', '', '', '', 'Google has removed ethics guidelines that previously barred its artificial intelligence systems from being used in weapons and surveillance.', 'As recently as January 30, the tech giant said its AI wouldn’t be used for weapons, surveillance, and other technologies that “cause or are likely to cause overall harm”.', 'The Independent has contacted Google for comment.', 'In a blog post Tuesday from senior company officials involved in AI, the company argued there’s “a global competition taking place for AI leadership within an increasingly complex geopolitical landscape.”', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” the post reads. “And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'In 2018, the company banned the use of its AI in weapons, after it faced internal protests over a Defense Department contract to use Google tech to analyze drone video.', 'The reported changes at Google align with a larger shift underway in the tech industry, which is showing increasing willingness to partner with U.S. defense and surveillance authorities, at the same time as many tech leaders like Elon Musk are shifting rightward politically.', 'In December, ChatGPT maker OpenAI announced a partnership with fellow tech company Anduril to develop technology for use in military defense against drones.', 'OpenAI had previously barred its technology from military use but changed its policies last year allow some collaborations.', 'OpenAI told The Wall Street Journal in a statement the technology developed with Anduril will only be used in defensive applications, and CEO Sam Altman said his company seeks to “ensure the technology upholds democratic values.”', 'Another major AI company, Anthropic, has a collaboration with tech company Palantir and Amazon Web Services to serve defense agencies.', 'And Palantir, Anduril, OpenAI, Saronic, and Scale AI are reportedly in talks with Musk’s aerospace firm SpaceX to form a consortium to bid on prime Pentagon contracts, in an attempt to challenge legacy contractors like Boeing and Lockheed Marin.', 'Despite its past alignment with Democratic candidates, the tech industry has made a concerted effort to work with the new administration, with tech companies lavishing Trump’s inaugural fund with million-dollar donations, and the CEOs of Meta, Amazon, Apple, and Google attending the swearing-in ceremony last month.', 'No one represents this shift more than Musk, who bucked his past support for Democrats and spent more than $290 million backing Trump and is now exercising unprecedented influence over the federal government’s spending priorities through his cost-cutting Department of Government Efficiency initiative, raising ethics alarms given the millions of dollars of contracts his companies have with the federal government.', 'The tech industry argues closer collaboration with the defense establishment is necessary given China’s rapid advances in AI, including the launch of DeepSeek, an AI assistant from a Chinese company that matches up against its U.S. competitors but was developed for a fraction of the cost, sending U.S. stocks tumbling.']"
Google pledge against using AI for weapons vanishes,https://www.malaymail.com/news/tech-gadgets/2025/02/05/google-pledge-against-using-ai-for-weapons-vanishes/165558,"['', '', '', 'ABOUT US', 'ADVERTISE', 'SAN FRANCISCO, Feb 5 — Google yesterday updated its principles when it comes to artificial intelligence, removing vows not to use the technology for weapons or surveillance.', 'Revised AI principles were posted just weeks after Google chief executive Sundar Pichai and other tech titans attended the inauguration of US President Donald Trump.', 'When asked by AFP about the change, a Google spokesperson referred to a blog post outlining the company’s AI principles that made no mention of the promises, which Pichai first outlined in 2018.', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” read an updated AI principles blog post by Google DeepMind chief Demis Hassabis and research labs senior vice president James Manyika.', '“And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,” it continued.', 'Pichai had previously stated that the company would not design or deploy the technology for weapons designed to hurt people or “that gather or use information for surveillance violating internationally accepted norms.”', 'That wording was gone from the updated AI principles shared by Google yesterday.', 'Upon taking office, Trump quickly rescinded an executive order by his predecessor, former president Joe Biden, mandating safety practices for AI.', 'Companies in the race to lead the burgeoning AI field in the United States now have fewer obligations to adhere to, such as being required to share test results signalling the technology has serious risks to the nation, its economy or its citizens.', 'Google noted in its blog post that it publishes an annual report about its AI work and progress.', '“There’s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,” Hassabis and Manyika said in their post.', '“Billions of people are using AI in their everyday lives.”', 'Google’s original AI principles were published after employee backlash to its involvement in a Pentagon research project looking into using AI to improve the ability of weapons systems to identify targets.', 'Google ended its involvement in the project. — AFP', '', '', 'Do Not Sell or Share My Personal Information', '', '', '']"
Google Drops Weapons and Surveillance Ban from AI Ethical Guidelines,https://www.yahoo.com/news/google-drops-weapons-surveillance-ban-015827718.html,"['', '', '', '', '', 'Google has gone back on a previous pledge not to use AI for weapons and surveillance, The Washington Post reported on Tuesday. Policies about “applications we will not pursue” from 2018 have been deleted from the company’s AI principles.', '“As recently as Jan. 30 [the list of banned applications] included weapons, surveillance, technologies that ’cause or are likely to cause overall harm,’ and use cases contravening principles of international law and human rights, according to a copy hosted by the Internet Archive,” the Post reported.', 'When asked for comment, a Google spokesperson directed TheWrap to a blog post from the company’s head of AI Demis Hassabis and SVP for technology and society James Manyika that promises transparency in the latest technological developments.', '“We believe democracies should lead in AI development, guided by core values like freedom, equality and respect for human rights. And we believe that companies, governments and organizations sharing these values should work together to create AI that protects people, promotes global growth and supports national security,” the blog reads.', 'Google’s updated AI principles state that the company will use human oversight to make sure the use of its technology conforms to “widely accepted principles of international law and human rights.”', 'The company first published its AI principles in 2018 after employees protested a contract with the Pentagon that used Google’s computer vision algorithms to analyze drone footage. The contract was not renewed.', 'Thousands of employees signed a letter addressed to CEO Sundar Pichai that stated, “We believe that Google should not be in the business of war.”', 'The post Google Drops Weapons and Surveillance Ban from AI Ethical Guidelines appeared first on TheWrap.']"
No title found,https://www.msn.com/en-gb/money/technology/google-drops-pledge-on-not-using-ai-for-weapons/ar-AA1yrBNF,"['Use precise geolocation data and actively scan device characteristics for identification. This is done to store and access information on a device and to provide personalised ads and content, ad and content measurement, audience insights and product development.\nList of Partners (vendors)', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']"
Google Lifts a Ban on Using Its AI for Weapons and Surveillance,https://www.wired.com/story/google-responsible-ai-principles/,"['Google announced Tuesday that it is overhauling the principles governing how it uses artificial intelligence and other advanced technology. The company removed language promising not to pursue “technologies that cause or are likely to cause overall harm,” “weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people,” “technologies that gather or use information for surveillance violating internationally accepted norms,” and “technologies whose purpose contravenes widely accepted principles of international law and human rights.”', 'The changes were disclosed in a note appended to the top of a 2018 blog post unveiling the guidelines. “We’ve made updates to our AI Principles. Visit AI.Google for the latest,” the note reads.', 'In a blog post on Tuesday, a pair of Google executives cited the increasingly widespread use of AI, evolving standards, and geopolitical battles over AI as the “backdrop” to why Google’s principles needed to be overhauled.', 'Google first published the principles in 2018 as it moved to quell internal protests over the company’s decision to work on a US military drone program. In response, it declined to renew the government contract and also announced a set of principles to guide future uses of its advanced technologies, such as artificial intelligence. Among other measures, the principles stated Google would not develop weapons, certain surveillance systems, or technologies that undermine human rights.', 'But in an announcement on Tuesday, Google did away with those commitments. The new webpage no longer lists a set of banned uses for Google’s AI initiatives. Instead, the revised document offers Google more room to pursue potentially sensitive use cases. It states Google will implement “appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.” Google also now says it will work to “mitigate unintended or harmful outcomes.”', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” wrote James Manyika, Google senior vice president for research, technology, and society, and Demis Hassabis, CEO of Google DeepMind, the company’s esteemed AI research lab. “And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'They added that Google will continue to focus on AI projects “that align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights.”', ""Multiple Google employees expressed concern about the changes in conversations with WIRED. “It's deeply concerning to see Google drop its commitment to the ethical use of AI technology without input from its employees or the broader public, despite long-standing employee sentiment that the company should not be in the business of war,” says Parul Koul, a Google software engineer and president of the Alphabet Union Workers-CWA."", 'Are you a current or former employee at Google? We’d like to hear from you. Using a nonwork phone or computer, contact Paresh Dave on Signal/WhatsApp/Telegram at +1-415-565-1302 or paresh_dave@wired.com, or Caroline Haskins on Signal at +1 785-813-1084 or at emailcarolinehaskins@gmail.com', 'US President Donald Trump’s return to office last month has galvanized many companies to revise policies promoting equity and other liberal ideals. Google spokesperson Alex Krasov says the changes have been in the works much longer.', 'Google lists its new goals as pursuing bold, responsible, and collaborative AI initiatives. Gone are phrases such as “be socially beneficial” and maintain “scientific excellence.” Added is a mention of “respecting intellectual property rights.”', 'After the initial release of its AI principles roughly seven years ago, Google created two teams tasked with reviewing whether projects across the company were living up to the commitments. One focused on Google’s core operations, such as search, ads, Assistant, and Maps. Another focused on Google Cloud offerings and deals with customers. The unit focused on Google’s consumer business was split up early last year as the company raced to develop chatbots and other generative AI tools to compete with OpenAI.', 'Timnit Gebru, a former colead of Google’s ethical AI research team who was later fired from that position, claims the company’s commitment to the principles had always been in question. “I would say that it’s better to not pretend that you have any of these principles than write them out and do the opposite,” she says.', 'Three former Google employees who had been involved in reviewing projects to ensure they aligned with the company’s principles say the work was challenging at times because of the varying interpretations of the principles and pressure from higher-ups to prioritize business imperatives.', 'Google still has language about preventing harm in its official Cloud Platform Acceptable Use Policy, which includes various AI-driven products. The policy forbids violating “the legal rights of others” and engaging in or promoting illegal activity, such as “terrorism or violence that can cause death, serious harm, or injury to individuals or groups of individuals.”', 'However, when pressed about how this policy squares with Project Nimbus—a cloud computing contract with the Israeli government, which has benefited the country’s military — Google has said that the agreement “is not directed at highly sensitive, classified, or military workloads relevant to weapons or intelligence services.”', '“The Nimbus contract is for workloads running on our commercial cloud by Israeli government ministries, who agree to comply with our Terms of Service and Acceptable Use Policy,” Google spokesperson Anna Kowalczyk told WIRED in July.', 'Google Cloud’s Terms of Service similarly forbid any applications that violate the law or “lead to death or serious physical harm to an individual.” Rules for some of Google’s consumer-focused AI services also ban illegal uses and some potentially harmful or offensive uses.', 'Update 2/04/25 5:45 ET: This story has been updated to include an additional comment from a Google employee.', 'Join the WIRED community to add comments.', 'Our latest scoop reveals the young, inexperienced engineers aiding Elon Musk’s government takeover', ""In your inbox: Get Plaintext—Steven Levy's long view on tech"", 'See the thousands of apps hijacked to spy on your location', 'Big Story: The king of Ozempic is scared as hell', 'Uncanny Valley: An insider look at the influence of Silicon Valley', 'MORE FROM WIRED', 'REVIEWS AND GUIDES', '© 2025 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices']"
No title found,https://www.dawn.com/news/1889887,"['Google on Tuesday updated its principles when it comes to artificial intelligence (AI), removing vows not to use the technology for weapons or surveillance.', 'Revised AI principles were posted just weeks after Google chief executive Sundar Pichai and other tech titans attended the inauguration of US President Donald Trump.', 'When asked by AFP about the change, a Google spokesperson referred to a blog post outlining the company’s AI principles that made no mention of the promises, which Pichai first outlined in 2018.', '', '', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” read an updated AI principles blog post by Google DeepMind chief Demis Hassabis and research labs senior vice president James Manyika.', '“And we believe that companies, governments, and organisations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,” it continued.', 'Pichai had previously stated that the company would not design or deploy the technology for weapons designed to hurt people or “that gather or use information for surveillance violating internationally accepted norms.”', 'That wording was gone from the updated AI principles shared by Google on Tuesday.', 'Upon taking office, Trump quickly rescinded an executive order by his predecessor, former president Joe Biden, mandating safety practices for AI.', 'Companies in the race to lead the burgeoning AI field in the United States now have fewer obligations to adhere to, such as being required to share test results signalling the technology has serious risks to the nation, its economy or its citizens.', 'Google noted in its blog post that it publishes an annual report about its AI work and progress.', '“There’s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,” Hassabis and Manyika said in their post.', '“Billions of people are using AI in their everyday lives.”', '', '', 'Google’s original AI principles were published after employee backlash to its involvement in a Pentagon research project looking into using AI to improve the ability of weapons systems to identify targets.', 'Google ended its involvement in the project.', 'Dear visitor, the comments section is undergoing an overhaul and will return soon.', '', 'Copyright © 2025, Dawn', 'NewsKit Publishing Platform\nby Compunode']"
Google pledge against using AI for weapons vanishes,https://www.victoriaadvocate.com/news/nation/google-pledge-against-using-ai-for-weapons-vanishes/article_199f1bdd-1341-51a8-a47e-a1875ca92838.html,"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']"
Google is suddenly fine with using AI for weapons and surveillance,https://www.indiatoday.in/technology/news/story/google-is-suddenly-fine-with-using-ai-for-weapons-and-surveillance-2675034-2025-02-05,"['Listen to Story', 'Google has suddenly revised its ethical guidelines for artificial intelligence (AI), removing the explicit ban on using the technology for weapons and surveillance. The update came on Tuesday via a blogpost shared by the company on the 2024 report on “Responsible AI”. This was first spotted by The Washington Post via the archived versions of the guidelines. The change in policy marks a critical shift from Google’s previous pledge to limit AI applications that could cause harm. The company had earlier committed that it will not use AI for applications that are “likely to cause overall harm”.', 'Google’s AI principles, which were first published in 2018, pledged against using the technology in four areas:\n-weapons\n-surveillance\n-applications likely to cause overall harm,\n-uses violating international law and human rights.', 'However, with the update to the AI guidelines, these restrictions have quietly been eliminated.', '', 'Meanwhile, Google’s head of AI, Demis Hassabis, and James Manyika, SVP for technology and society, wrote in the blogpost: “We are investing more than ever in both AI research and products that benefit people and society, and in AI safety and efforts to identify and address potential risks”.', '“There’s a global competition for AI leadership within an increasingly complex geopolitical environment. We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” the post further reads –– which also sounds like Google trying to convince the reader that lifting the ban on using AI for weapons and surveillance has only been done with the greater good in mind.', 'When Google first announced its AI principles in 2018, it was after a huge protest by Google employees against a then-ongoing Project Maven. It was a Pentagon contract that needed to use AI for drone surveillance. However, Google employees were opposed to using the tech they built for surveillance, so after pressure from the workers, Google was forced to withdraw from the project. Now, the change in policy, however, shows a renewed willingness to use AI for surveillance, once again.', '', 'Google isn’t the only company that is working with AI and is open to providing its tech to the local government. Companies like OpenAI and Anthropic are also deeply involved with the US defence authorities. This change also makes the increased collaboration between tech companies and national security agencies quite evident.', 'Just last week, after the US President Donald Trump said that he wanted to rename the Gulf of Mexico to the Gulf of America, Google quietly agreed without any protest, and said that it has a policy to do so. As long as the change in name is reflected in official records in the US, it can make that change for Google Maps users in the US.', '']"
Google pledge against using AI for weapons vanishes,https://www.elkharttruth.com/news/national/google-pledge-against-using-ai-for-weapons-vanishes/article_8e2a3334-fb53-50b2-a3e2-a6933164703f.html,"['', '', '', '', '', '', '', '', '', '', '', '', ""Google's original principles when it came to developing artificial intelligence were not to use it for weapons or surveillance that could infringe on people's rights"", 'Google on Tuesday updated its principles when it comes to artificial intelligence, removing vows not to use the technology for weapons or surveillance.', 'Revised AI principles were posted just weeks after Google chief executive Sundar Pichai and other tech titans attended the inauguration of US President Donald Trump.', 'Originally published on doc.afp.com, part of the BLOX Digital Content Exchange.', 'Log In', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']"
Google Removes Language on Weapons From Public AI Principles,https://www.bloomberg.com/news/articles/2025-02-04/google-removes-language-on-weapons-from-public-ai-principles,"['', '', '', '', '', '', '', '', 'The AI Race:', 'Alphabet Inc.’s Google removed a passage from its artificial intelligence principles that pledged to avoid using the technology in potentially harmful applications, such as weapons.', '', '', 'By accepting, you agree to our updated Terms of Service, including the arbitration provision and class action waiver. You understand that we process your information as described in the Privacy Policy, which may include sharing information about your use of Bloomberg.com with third parties.']"
Google removes guidelines barring its AI from being used in surveillance and weapons: report,https://www.the-independent.com/tech/google-ai-surveillance-security-trump-b2692301.html,"['', 'Company banned use of its AI in weapons in 2018 and just last month insisted it would not be used for anything ‘likely to cause overall harm’', '', '', ""From reproductive rights to climate change to Big Tech, The Independent is on the ground when the story is developing. Whether it's investigating the financials of Elon Musk's pro-Trump PAC or producing our latest documentary, 'The A Word', which shines a light on the American women fighting for reproductive rights, we know how important it is to parse out the facts from the messaging."", '', '', 'Google has reportedly removed ethics guidelines that previously barred its artificial intelligence systems from being used in weapons and surveillance.', 'As recently as January 30, the tech giant said its AI wouldn’t be used for weapons, surveillance, and other technologies that “cause or are likely to cause overall harm,” The Washington Post reports.', 'The Independent has contacted Google for comment.', 'In a blog post Tuesday from senior company officials involved in AI, the company argued there’s “a global competition taking place for AI leadership within an increasingly complex geopolitical landscape.”', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” the post reads. “And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'In 2018, the company banned the use of its AI in weapons, after it faced internal protests over a Defense Department contract to use Google tech analyze drone video.', 'The reported changes at Google align with a larger shift underway in the tech industry, which is showing increasing willingness to partner with U.S. defense and surveillance authorities, at the same time as many tech leaders like Elon Musk are shifting rightward politically.', 'In December, ChatGPT maker OpenAI announced a partnership with fellow tech company Anduril to develop technology for use in military defense against drones.', 'OpenAI had previously barred its technology from military use but changed its last year allow some collaborations.', 'OpenAI told The Wall Street Journal in a statement the technology developed with Anduril will only be used in defensive applications, and CEO Sam Altman said his company seeks to “ensure the technology upholds democratic values.”', 'Another major AI company, Anthropic, has a collaboration with tech company Palantir and Amazon Web Services to serve defense agencies.', 'And Palantir, Anduril, OpenAI, Saronic, and Scale AI are reportedly in talks with Musk’s aerospace firm SpaceX to form a consortium to bid on prime Pentagon contracts, in an attempt to challenge legacy contractors like Boeing and Lockheed Marin.', 'Despite its past alignment with Democratic candidates, the tech industry has made a concerted effort to work with the new administration, with tech companies lavishing Trump’s inaugural fund with million-dollar donations, and the CEOs of Meta, Amazon, Apple, and Google attending the swearing-in ceremony last month.', 'No one represents this shift more than Musk, who bucked his past support for Democrats and spent more than $290 million backing Trump and is now exercising unprecedented influence over the federal government’s spending priorities through his cost-cutting Department of Government Efficiency initiative, raising ethics alarms given the millions of dollars of contracts his companies have with the federal government.', 'The tech industry argues closer collaboration with the defense establishment is necessary given China’s rapid advances in AI, including the launch of DeepSeek, an AI assistant from a Chinese company that matches up against its U.S. competitors but was developed for a fraction of the cost, sending U.S. stocks tumbling.', 'Join thought-provoking conversations, follow other Independent readers and see their replies', '']"
No title found,https://www.msn.com/en-us/news/technology/google-drops-pledge-not-to-use-ai-for-weapons-or-surveillance/ar-AA1ypHM5,[]
Google's U-turn: Removes pledge not to build AI for weapons,https://www.newsbytesapp.com/news/science/google-revises-ai-principles-no-longer-rules-out-military-applications/story,"['', '', ""Alphabet, Google's parent company, has updated its guidelines on artificial intelligence (AI) use."", 'The new principles no longer include a commitment to stay away from using AI for things like weapon development and surveillance tools.', 'This is a major departure from the firm\'s previous stance that explicitly ruled out uses ""likely to cause harm.""', 'Guideline shift', 'Notably, the revised guidelines also include a section on ""responsible development and deployment.""', 'In this, Google promises to implement ""appropriate human oversight, due diligence, and feedback mechanisms.""', 'The idea is to ensure that the AI aligns with user goals, social responsibility, and widely accepted principles of international law and human rights.', ""This change shows how Google's approach toward AI use is evolving."", 'Defense stance', ""Google's Senior Vice President, James Manyika, and head of the AI lab Google DeepMind, Demis Hassabis, have defended the revision in a blog post."", 'They argue that businesses and democratic governments need to collaborate on AI that ""supports national security.""', 'The defense comes amid ongoing debates among AI experts about the governance of this powerful new technology and its potential risks to humanity.', 'Principle evolution', ""The blog post further detailed that the firm's original AI principles, published in 2018, needed to be updated in light of technological advancements."", '""Billions of people are using AI in their everyday lives. It has moved from a niche research topic in the lab to a technology that is becoming as pervasive as mobile phones and the internet itself,"" the post read.', 'Geopolitical influence', 'In their blog post, Hassabis and Manyika noted the growing complexity of the geopolitical landscape.', 'They stressed their belief that democracies should take the lead in AI development, driven by core values such as freedom, equality, and respect for human rights.', 'The executives also called for collaboration between companies, governments, and organizations with these values to develop AI that protects people, drives global growth, and supports national security.', 'Financial outlook', ""The blog post came just ahead of Alphabet's end-of-year financial report, which revealed weaker-than-expected results, affecting its share price."", 'That was despite a 10% rise in revenue from digital advertising - largely due to US election spending. Now, the company intends to spend $75 billion on AI projects this year.', 'This will be directed toward infrastructure for running AI, AI research, and applications like AI-powered search.']"
Google now thinks it's OK to use AI for weapons and surveillance,https://www.engadget.com/ai/google-now-thinks-its-ok-to-use-ai-for-weapons-and-surveillance-224824373.html,"['Google has made one of the most substantive changes to its AI principles since first publishing them in 2018. In a change spotted by The Washington Post, the search giant edited the document to remove pledges it had made promising it would not ""design or deploy"" AI tools for use in weapons or surveillance technology. Previously, those guidelines included a section titled ""applications we will not pursue,"" which is not present in the current version of the document.', 'Instead, there\'s now a section titled ""responsible development and deployment."" There, Google says it will implement ""appropriate human oversight, due diligence, and feedback mechanisms to align with user goals, social responsibility, and widely accepted principles of international law and human rights.""', 'That\'s a far broader commitment than the specific ones the company made as recently as the end of last month when the prior version of its AI principles was still live on its website. For instance, as it relates to weapons, the company previously said it would not design AI for use in ""weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.” As for AI surveillance tools, the company said it would not develop tech that violates ""internationally accepted norms.""', 'When asked for comment, a Google spokesperson pointed Engadget to a blog post the company published on Thursday. In it, DeepMind CEO Demis Hassabis and James Manyika, senior vice president of research, labs, technology and society at Google, say AI\'s emergence as a ""general-purpose technology"" necessitated a policy change.', '""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights. And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,"" the two wrote. ""… Guided by our AI Principles, we will continue to focus on AI research and applications that align with our mission, our scientific focus, and our areas of expertise, and stay consistent with widely accepted principles of international law and human rights — always evaluating specific work by carefully assessing whether the benefits substantially outweigh potential risks.""', 'When Google first published its AI principles in 2018, it did so in the aftermath of Project Maven. It was a controversial government contract that, had Google decided to renew it, would have seen the company provide AI software to the Department of Defense for analyzing drone footage. Dozens of Google employees quit the company in protest of the contract, with thousands more signing a petition in opposition. When Google eventually published its new guidelines, CEO Sundar Pichai reportedly told staff his hope was they would stand ""the test of time.""', 'By 2021, however, Google began pursuing military contracts again, with what was reportedly an ""aggressive"" bid for the Pentagon\'s Joint Warfighting Cloud Capability cloud contract. At the start of this year, The Washington Post reported that Google employees had repeatedly worked with Israel\'s Defense Ministry to expand the government\'s use of AI tools.']"
Google pledge against using AI for weapons vanishes,https://www.wataugademocrat.com/news/national/google-pledge-against-using-ai-for-weapons-vanishes/article_fe65c48f-1b7f-53e2-ab70-138a32e7bcf5.html,"['', '', ""Google's original principles when it came to developing artificial intelligence were not to use it for weapons or surveillance that could infringe on people's rights"", 'Google on Tuesday updated its principles when it comes to artificial intelligence, removing vows not to use the technology for weapons or surveillance.', 'Revised AI principles were posted just weeks after Google chief executive Sundar Pichai and other tech titans attended the inauguration of US President Donald Trump.', ""When asked by AFP about the change, a Google spokesperson referred to a blog post outlining the company's AI principles that made no mention of the promises, which Pichai first outlined in 2018."", '', '""We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,"" read an updated AI principles blog post by Google DeepMind chief Demis Hassabis and research labs senior vice president James Manyika.', '""And we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security,"" it continued.', 'Pichai had previously stated that the company would not design or deploy the technology for weapons designed to hurt people or ""that gather or use information for surveillance violating internationally accepted norms.""', 'That wording was gone from the updated AI principles shared by Google on Tuesday.', 'Upon taking office, Trump quickly rescinded an executive order by his predecessor, former president Joe Biden, mandating safety practices for AI.', 'Companies in the race to lead the burgeoning AI field in the United States now have fewer obligations to adhere to, such as being required to share test results signalling the technology has serious risks to the nation, its economy or its citizens.', 'Google noted in its blog post that it publishes an annual report about its AI work and progress.', '""There\'s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape,"" Hassabis and Manyika said in their post.', '""Billions of people are using AI in their everyday lives.""', ""Google's original AI principles were published after employee backlash to its involvement in a Pentagon research project looking into using AI to improve the ability of weapons systems to identify targets."", 'Google ended its involvement in the project.', 'gc-juj/jgc', 'Originally published on doc.afp.com, part of the BLOX Digital Content Exchange.', 'Dear reader,', ""Thanks to modern technologies, you and more people are reading the Watauga Democrat than ever before. Freedom of the press is essential to preserving democracy: But a free press isn't free. It takes significant resources for Mountain Times Publications' 8 full-time reporters and editors to provide credible, fact-based and ethical journalism in the High Country. So, we are asking you to join our advertisers and print subscribers in supporting local journalism with your dollar.\nYour financial support will help sustain these services that you use to inform your decisions and engage with your community.\nCLICK HERE TO MAKE A CONTRIBUTION"", 'Log In', '', ""We're always interested in hearing about news in our community. Let us know what's going on!"", ""Thanks to modern technologies, you and more people are reading the Watauga Democrat than ever before. Freedom of the press is essential to preserving democracy: But a free press isn't free. It takes significant resources for Mountain Times Publications' 8 full-time journalists and editors to provide credible, fact-based and ethical journalism in the High Country. So, we are asking you to join our advertisers and print subscribers in supporting local journalism with your dollar. Your financial support will help sustain these services that you use to inform your decisions and engage with your community."", '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Learn more about your privacy options', '', '', '']"
Google erases promise not to use AI technology for weapons or surveillance,https://www.aol.com/google-erases-promise-not-ai-222416539.html,"['', '', 'Google’s updated, public AI ethics policy removes its promise that it won’t use the technology to pursue applications for weapons and surveillance.', 'In a previous version of the principles seen by CNN on the internet archive Wayback Machine, the company included applications it won’t pursue. One such category was weapons or other technology intended to injure people. Another was technology used to surveil beyond international norms.', 'That language is gone on the updated principles page.', 'Since OpenAI launched chatbot ChatGPT in 2022, the artificial intelligence race has advanced at a dizzying pace. While AI has boomed in use, legislation and regulations on transparency and ethics in AI have yet to catch up – and now Google seems to have loosened self-imposed restrictions.', 'In a blog post Tuesday, senior vice president of research, labs, technology & society James Manyika and Google DeepMind head Demis Hassabis said that AI frameworks published by democratic countries have deepened Google’s “understanding of AI’s potential and risks.”', '“There’s a global competition taking place for AI leadership within an increasingly complex geopolitical landscape. We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” the blog post said.', 'The post continued, “and we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'Google first published its AI Principles in 2018, years before the technology became almost ubiquitous. Google’s update is a sharp reversal in values from those original published principles.', 'In 2018, Google dropped a $10 billion bid for a cloud computing Pentagon contract, saying at the time “we couldn’t be assured that it would align with our AI Principles.” More than 4,000 employees had signed a petition that year demanding “a clear policy stating that neither Google nor its contractors will ever build warfare technology,” and about a dozen employees resigned in protest.', 'CNN has reached out to Google for comment.', 'CNN’s Jordan Valinsky contributed to this report.', 'For more CNN news and newsletters create an account at CNN.com', 'Advertisement']"
Google removes language on weapons from public AI principles,https://www.scmp.com/tech/big-tech/article/3297394/google-removes-language-weapons-public-ai-principles,"['Removing the ‘harm’ clause may have implications for the type of work Google will pursue, said a former Google AI researcher', 'Alphabet’s Google has removed a key passage about applications it will not pursue from its publicly listed artificial intelligence principles, which guide the tech giant’s work in the industry.', 'The company’s AI Principles previously included a passage titled “applications we will not pursue,” such as “technologies that cause or are likely to cause overall harm”, including weapons, according to screenshots viewed by Bloomberg. That language is no longer visible on the page.', '“We believe democracies should lead in AI development, guided by core values like freedom, equality, and respect for human rights,” Google said in a blog post Tuesday. “And we believe that companies, governments, and organisations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”', 'Removing the “harm” clause may have implications for the type of work Google will pursue, said Margaret Mitchell, a former Google AI researcher.', '“Having that removed is erasing the work that so many people in the ethical AI space and the activist space as well had done at Google, and more problematically it means Google will probably now work on deploying technology directly that can kill people,” she said.', 'Google did not immediately respond to a request for comment on its specific plans.', '']"
